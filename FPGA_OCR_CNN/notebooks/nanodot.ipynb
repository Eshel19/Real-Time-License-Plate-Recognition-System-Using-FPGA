{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine dataset and resize\n",
    "\n",
    "Step 1: Resize Images and Create Initial JSON\n",
    "Resize all the images and rename them according to the new IDs.\n",
    "\n",
    "Create a JSON file for each sub-dataset (without annotations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "def resize_image(image_path, size):\n",
    "    image = Image.open(image_path)\n",
    "    orig_size = image.size\n",
    "    image = image.resize(size, Image.LANCZOS)\n",
    "    return image, orig_size\n",
    "\n",
    "def create_initial_json(subset, dataset_names):\n",
    "    combined = {\n",
    "        \"images\": [],\n",
    "        \"categories\": [{\"id\": 0, \"name\": \"0\"}, {\"id\": 1, \"name\": \"1\"}],\n",
    "        \"info\": {\"description\": f\"Combined {subset} dataset\"},\n",
    "        \"licenses\": [{\"id\": 1, \"name\": \"Default\"}]\n",
    "    }\n",
    "\n",
    "    img_id_offset = 0\n",
    "    existing_image_names = set()\n",
    "\n",
    "    for dataset_name in dataset_names:\n",
    "        source_folder = os.path.join(f\"dataset_coco/{dataset_name}/{subset}\")\n",
    "        dest_folder = os.path.join(f\"dataset_coco/combined_dataset/{subset}\")\n",
    "        os.makedirs(dest_folder, exist_ok=True)\n",
    "\n",
    "        annotation_file = os.path.join(source_folder, \"_annotations.coco.json\")\n",
    "\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        for img in data[\"images\"]:\n",
    "            image_path = os.path.join(source_folder, img[\"file_name\"])\n",
    "            new_image_name = f\"{img_id_offset}.jpg\"\n",
    "\n",
    "            while new_image_name in existing_image_names:\n",
    "                new_image_name = f\"{img_id_offset}_renamed.jpg\"\n",
    "\n",
    "            existing_image_names.add(new_image_name)\n",
    "            dest_image_path = os.path.join(dest_folder, new_image_name)\n",
    "\n",
    "            if os.path.exists(image_path):\n",
    "                resized_image, orig_size = resize_image(image_path, (128, 128))\n",
    "                resized_image.save(dest_image_path)\n",
    "\n",
    "            new_img = {\n",
    "                \"id\": img_id_offset,\n",
    "                \"file_name\": new_image_name,\n",
    "                \"width\": 128,\n",
    "                \"height\": 128,\n",
    "                \"license\": 1,\n",
    "                \"source_dataset\": dataset_name,\n",
    "                \"id_in_dataset\": img[\"id\"]\n",
    "            }\n",
    "            combined[\"images\"].append(new_img)\n",
    "\n",
    "            img_id_offset += 1\n",
    "\n",
    "    json_file_path = os.path.join(f\"dataset_coco/combined_dataset/{subset}\", f\"{subset}_initial.json\")\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        json.dump(combined, json_file, indent=4)\n",
    "\n",
    "# Example usage for each subset\n",
    "create_initial_json(\"train\", [\"Dataset1\", \"Dataset2\", \"Dataset3\", \"Dataset4\"])\n",
    "create_initial_json(\"valid\", [\"Dataset1\", \"Dataset2\", \"Dataset3\", \"Dataset4\"])\n",
    "create_initial_json(\"test\", [\"Dataset1\", \"Dataset2\", \"Dataset3\", \"Dataset4\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Copy and Adjust Annotations\n",
    "Read the initial JSON file.\n",
    "\n",
    "Copy annotations from the original datasets and adjust them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def adjust_annotations(annotations, x_scale, y_scale, size, img_id, ann_id_offset):\n",
    "    updated_annotations = []\n",
    "    for ann in annotations:\n",
    "        ann[\"bbox\"][0] *= x_scale\n",
    "        ann[\"bbox\"][1] *= y_scale\n",
    "        ann[\"bbox\"][2] *= x_scale\n",
    "        ann[\"bbox\"][3] *= y_scale\n",
    "\n",
    "        ann[\"bbox\"][0] = max(0, min(ann[\"bbox\"][0], size[0] - ann[\"bbox\"][2]))\n",
    "        ann[\"bbox\"][1] = max(0, min(ann[\"bbox\"][1], size[1] - ann[\"bbox\"][3]))\n",
    "        ann[\"bbox\"][2] = min(ann[\"bbox\"][2], size[0])\n",
    "        ann[\"bbox\"][3] = min(ann[\"bbox\"][3], size[1])\n",
    "\n",
    "        ann[\"area\"] = ann[\"bbox\"][2] * ann[\"bbox\"][3]\n",
    "\n",
    "        if \"segmentation\" in ann:\n",
    "            new_segmentation = []\n",
    "            for seg in ann[\"segmentation\"]:\n",
    "                new_seg = []\n",
    "                for i in range(0, len(seg), 2):\n",
    "                    x = seg[i] * x_scale\n",
    "                    y = seg[i + 1] * y_scale\n",
    "                    new_seg.append(x)\n",
    "                    new_seg.append(y)\n",
    "                new_segmentation.append(new_seg)\n",
    "            ann[\"segmentation\"] = new_segmentation\n",
    "\n",
    "        ann[\"category_id\"] = 0 if ann[\"category_id\"] != 1 else 1\n",
    "        ann[\"image_id\"] = img_id\n",
    "\n",
    "        ann[\"id\"] = ann_id_offset\n",
    "        ann_id_offset += 1\n",
    "\n",
    "        updated_annotations.append(ann)\n",
    "    return updated_annotations, ann_id_offset\n",
    "\n",
    "def copy_and_adjust_annotations(subset, dataset_names):\n",
    "    initial_json_path = os.path.join(f\"dataset_coco/combined_dataset/{subset}\", f\"{subset}_initial.json\")\n",
    "    \n",
    "    with open(initial_json_path, 'r') as f:\n",
    "        combined = json.load(f)\n",
    "\n",
    "    annotations = []\n",
    "    ann_id_offset = 0\n",
    "\n",
    "    for img in combined[\"images\"]:\n",
    "        dataset_name = img[\"source_dataset\"]\n",
    "        img_id_in_dataset = img[\"id_in_dataset\"]\n",
    "\n",
    "        source_folder = os.path.join(f\"dataset_coco/{dataset_name}/{subset}\")\n",
    "        annotation_file = os.path.join(source_folder, \"_annotations.coco.json\")\n",
    "\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        orig_img = next((i for i in data[\"images\"] if i[\"id\"] == img_id_in_dataset), None)\n",
    "        if orig_img:\n",
    "            orig_size = (orig_img[\"width\"], orig_img[\"height\"])\n",
    "            x_scale = img[\"width\"] / orig_size[0]\n",
    "            y_scale = img[\"height\"] / orig_size[1]\n",
    "\n",
    "            image_annotations = [ann for ann in data[\"annotations\"] if ann[\"image_id\"] == img_id_in_dataset]\n",
    "            updated_annotations_batch, ann_id_offset = adjust_annotations(image_annotations, x_scale, y_scale, (128, 128), img[\"id\"], ann_id_offset)\n",
    "            annotations.extend(updated_annotations_batch)\n",
    "\n",
    "    combined[\"annotations\"] = annotations\n",
    "    combined_json_path = os.path.join(f\"dataset_coco/combined_dataset/{subset}\", f\"{subset}_annotations.coco.json\")\n",
    "    \n",
    "    with open(combined_json_path, 'w') as json_file:\n",
    "        json.dump(combined, json_file, indent=4)\n",
    "\n",
    "# Example usage for each subset\n",
    "copy_and_adjust_annotations(\"train\", [\"Dataset1\", \"Dataset2\", \"Dataset3\", \"Dataset4\"])\n",
    "copy_and_adjust_annotations(\"valid\", [\"Dataset1\", \"Dataset2\", \"Dataset3\", \"Dataset4\"])\n",
    "copy_and_adjust_annotations(\"test\", [\"Dataset1\", \"Dataset2\", \"Dataset3\", \"Dataset4\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confirming that the resize work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_bounding_boxes(image_path, annotations):\n",
    "    image = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    for ann in annotations:\n",
    "        bbox = ann['bbox']\n",
    "        x, y, width, height = bbox\n",
    "        draw.rectangle([x, y, x + width, y + height], outline='red', width=2)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def select_random_images_and_display(dataset_folder, combined_annotations_file, num_images=5):\n",
    "    with open(combined_annotations_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    images = data['images']\n",
    "    annotations = data['annotations']\n",
    "    \n",
    "    selected_images = random.sample(images, num_images)\n",
    "    \n",
    "    for img in selected_images:\n",
    "        image_id = img['id']\n",
    "        image_file = img['file_name']\n",
    "        image_path = os.path.join(dataset_folder, image_file)\n",
    "        \n",
    "        img_annotations = [ann for ann in annotations if ann['image_id'] == image_id]\n",
    "        \n",
    "        image_with_boxes = draw_bounding_boxes(image_path, img_annotations)\n",
    "        \n",
    "        # Display the image\n",
    "        plt.figure()\n",
    "        plt.imshow(image_with_boxes)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "dataset_folder = \"dataset_coco/combined_dataset/valid\"\n",
    "combined_annotations_file = os.path.join(dataset_folder, \"valid_annotations.coco.json\")\n",
    "\n",
    "select_random_images_and_display(dataset_folder, combined_annotations_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize dataset old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def resize_image_and_boxes(image, boxes, output_size):\n",
    "    h, w = image.shape[:2]\n",
    "    scale_factor_w = w / output_size[0]\n",
    "    scale_factor_h = h / output_size[1]\n",
    "    resized_image = cv2.resize(image, output_size)\n",
    "    resized_boxes = [[coord / scale_factor_w if i % 2 == 0 else coord / scale_factor_h for i, coord in enumerate(box)] for box in boxes]\n",
    "    return resized_image, resized_boxes, scale_factor_w, scale_factor_h\n",
    "\n",
    "def resize_coco_annotations(input_json_path, output_json_path, output_size):\n",
    "    with open(input_json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for image_info in data['images']:\n",
    "        h, w = image_info['height'], image_info['width']\n",
    "        scale_factor_w = w / output_size[0]\n",
    "        scale_factor_h = h / output_size[1]\n",
    "        image_info['height'] = output_size[1]\n",
    "        image_info['width'] = output_size[0]\n",
    "\n",
    "        for annotation in data['annotations']:\n",
    "            if annotation['image_id'] == image_info['id']:\n",
    "                bbox = annotation['bbox']\n",
    "                annotation['bbox'] = [bbox[0] / scale_factor_w, bbox[1] / scale_factor_h, bbox[2] / scale_factor_w, bbox[3] / scale_factor_h]\n",
    "                if 'segmentation' in annotation:\n",
    "                    annotation['segmentation'] = [\n",
    "                        [point / scale_factor_w if i % 2 == 0 else point / scale_factor_h for i, point in enumerate(segment)]\n",
    "                        for segment in annotation['segmentation']\n",
    "                    ]\n",
    "\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "def draw_bounding_boxes(image, boxes, color=(0, 255, 0)):\n",
    "    for box in boxes:\n",
    "        x, y, w, h = map(int, box)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "    return image\n",
    "\n",
    "def display_images_with_boxes(images_with_boxes):\n",
    "    for resized_image, original_image in images_with_boxes:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(\"Resized Image with Boxes\")\n",
    "        plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(\"Original Image with Rescaled Boxes\")\n",
    "        plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "def process_dataset(input_dir, output_dir, input_json_path, output_json_path, output_size, sample_count=5):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    with open(input_json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    sample_images = []\n",
    "    for i, image_info in enumerate(data['images']):\n",
    "        image_path = os.path.join(input_dir, image_info['file_name'])\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "\n",
    "        annotations = [ann for ann in data['annotations'] if ann['image_id'] == image_info['id']]\n",
    "        boxes = [ann['bbox'] for ann in annotations]\n",
    "\n",
    "        resized_image, resized_boxes, scale_factor_w, scale_factor_h = resize_image_and_boxes(image, boxes, output_size)\n",
    "        resized_image_path = os.path.join(output_dir, image_info['file_name'])\n",
    "        cv2.imwrite(resized_image_path, resized_image)\n",
    "\n",
    "        for ann, box in zip(annotations, resized_boxes):\n",
    "            ann['bbox'] = box\n",
    "\n",
    "        if i < sample_count:\n",
    "            # Draw bounding boxes on resized image\n",
    "            resized_image_with_boxes = draw_bounding_boxes(resized_image.copy(), resized_boxes)\n",
    "\n",
    "            # Rescale boxes back to original size and draw on original image\n",
    "            original_boxes = [[coord * scale_factor_w if i % 2 == 0 else coord * scale_factor_h for i, coord in enumerate(box)] for box in resized_boxes]\n",
    "            original_image_with_boxes = draw_bounding_boxes(image.copy(), original_boxes, color=(255, 0, 0))\n",
    "\n",
    "            sample_images.append((resized_image_with_boxes, original_image_with_boxes))\n",
    "\n",
    "    resize_coco_annotations(input_json_path, output_json_path, output_size)\n",
    "\n",
    "    display_images_with_boxes(sample_images)\n",
    "\n",
    "# Paths\n",
    "input_dir = 'dataset_coco/train'\n",
    "output_dir = 'dataset_128x128/train'\n",
    "input_json_path = os.path.join(input_dir, '_annotations.coco.json')\n",
    "output_json_path = os.path.join(output_dir, '_annotations.coco.json')\n",
    "\n",
    "# Parameters\n",
    "output_size = (128, 128)  # Desired output resolution\n",
    "sample_count = 5  # Number of sample images to save for verification\n",
    "\n",
    "# Process dataset\n",
    "process_dataset(input_dir, output_dir, input_json_path, output_json_path, output_size, sample_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vailodata model NCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import ncnn\n",
    "\n",
    "class NanoDet:\n",
    "    def __init__(self, param_path, bin_path, num_threads=2, target_size=128, prob_threshold=0.6, nms_threshold=0.65):\n",
    "        self.net = ncnn.Net()\n",
    "        self.net.load_param(param_path)\n",
    "        self.net.load_model(bin_path)\n",
    "        self.num_threads = num_threads\n",
    "        self.target_size = target_size\n",
    "        self.prob_threshold = prob_threshold\n",
    "        self.nms_threshold = nms_threshold\n",
    "        self.net.opt.num_threads = num_threads\n",
    "        self.net.opt.use_packing_layout = True\n",
    "        self.net.opt.use_fp16_packed = True\n",
    "        self.net.opt.use_fp16_storage = True\n",
    "        self.net.opt.use_fp16_arithmetic = True\n",
    "        self.net.opt.use_int8_inference = True\n",
    "        self.net.opt.use_vulkan_compute = False\n",
    "\n",
    "    def detect(self, bgr):\n",
    "        width = bgr.shape[1]\n",
    "        height = bgr.shape[0]\n",
    "\n",
    "        # pad to multiple of 32\n",
    "        w, h, scale = width, height, 1.0\n",
    "        if w > h:\n",
    "            scale = self.target_size / w\n",
    "            w, h = self.target_size, int(h * scale)\n",
    "        else:\n",
    "            scale = self.target_size / h\n",
    "            h, w = self.target_size, int(w * scale)\n",
    "\n",
    "        in_resized = cv2.resize(bgr, (w, h))\n",
    "        wpad = (w + 31) // 32 * 32 - w\n",
    "        hpad = (h + 31) // 32 * 32 - h\n",
    "        in_padded = cv2.copyMakeBorder(in_resized, hpad // 2, hpad - hpad // 2, wpad // 2, wpad - wpad // 2, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "        in_padded = in_padded.astype(np.float32)\n",
    "        mean_vals = [103.53, 116.28, 123.675]\n",
    "        norm_vals = [0.017429, 0.017507, 0.017125]\n",
    "        in_padded -= mean_vals\n",
    "        in_padded *= norm_vals\n",
    "\n",
    "        mat_in = ncnn.Mat.from_pixels(in_padded, ncnn.Mat.PixelType.PIXEL_BGR2RGB, in_padded.shape[1], in_padded.shape[0])\n",
    "        ex = self.net.create_extractor()\n",
    "        ex.input(\"in0\", mat_in)\n",
    "\n",
    "        proposals = []\n",
    "        for stride, layer_id in zip([8, 16, 32], [\"150\", \"160\", \"170\"]):\n",
    "            out = ncnn.Mat()\n",
    "            ex.extract(layer_id, out)\n",
    "            self.generate_proposals(out, stride, mat_in, proposals)\n",
    "\n",
    "        proposals.sort(key=lambda x: -x[4])  # Sort by score\n",
    "\n",
    "        picked = []\n",
    "        self.nms_sorted_bboxes(proposals, picked)\n",
    "\n",
    "        objects = []\n",
    "        for i in picked:\n",
    "            obj = proposals[i]\n",
    "            x0, y0 = (obj[0] - wpad / 2) / scale, (obj[1] - hpad / 2) / scale\n",
    "            x1, y1 = (obj[2] - wpad / 2) / scale, (obj[3] - hpad / 2) / scale\n",
    "            obj = [x0, y0, x1, y1, obj[4], obj[5]]\n",
    "            objects.append(obj)\n",
    "        \n",
    "        return objects\n",
    "\n",
    "    def generate_proposals(self, pred, stride, in_pad, proposals):\n",
    "        num_grid_x = pred.w\n",
    "        num_grid_y = pred.h\n",
    "        num_class = 2\n",
    "        reg_max_1 = (pred.c - num_class) // 4\n",
    "\n",
    "        for i in range(num_grid_y):\n",
    "            for j in range(num_grid_x):\n",
    "                # find label with max score\n",
    "                label = -1\n",
    "                score = -float('inf')\n",
    "                for k in range(1, num_class):\n",
    "                    s = pred.channel(k).row(i)[j]\n",
    "                    if s > score:\n",
    "                        label = k\n",
    "                        score = s\n",
    "\n",
    "                score = 1.0 / (1.0 + np.exp(-score))\n",
    "\n",
    "                if score >= self.prob_threshold:\n",
    "                    bbox_pred = np.zeros((4, reg_max_1))\n",
    "                    for k in range(reg_max_1 * 4):\n",
    "                        bbox_pred[k // reg_max_1, k % reg_max_1] = pred.channel(num_class + k).row(i)[j]\n",
    "\n",
    "                    bbox_pred = np.apply_along_axis(self.soft_max, axis=1, arr=bbox_pred)\n",
    "\n",
    "                    pred_ltrb = []\n",
    "                    for k in range(4):\n",
    "                        dis = np.dot(np.arange(reg_max_1), bbox_pred[k])\n",
    "                        pred_ltrb.append(dis * stride)\n",
    "\n",
    "                    pb_cx = j * stride\n",
    "                    pb_cy = i * stride\n",
    "                    x0 = pb_cx - pred_ltrb[0]\n",
    "                    y0 = pb_cy - pred_ltrb[1]\n",
    "                    x1 = pb_cx + pred_ltrb[2]\n",
    "                    y1 = pb_cy + pred_ltrb[3]\n",
    "\n",
    "                    proposals.append([x0, y0, x1, y1, score, label])\n",
    "\n",
    "    def soft_max(self, x):\n",
    "        exp_x = np.exp(x - np.max(x))\n",
    "        return exp_x / exp_x.sum(axis=0)\n",
    "\n",
    "    def nms_sorted_bboxes(self, faceobjects, picked, nms_threshold=0.65, agnostic=False):\n",
    "        picked.clear()\n",
    "\n",
    "        n = len(faceobjects)\n",
    "        areas = [(x[2] - x[0]) * (x[3] - x[1]) for x in faceobjects]\n",
    "\n",
    "        for i in range(n):\n",
    "            keep = True\n",
    "            for j in picked:\n",
    "                if not agnostic and faceobjects[i][5] != faceobjects[j][5]:\n",
    "                    continue\n",
    "\n",
    "                inter_x1 = max(faceobjects[i][0], faceobjects[j][0])\n",
    "                inter_y1 = max(faceobjects[i][1], faceobjects[j][1])\n",
    "                inter_x2 = min(faceobjects[i][2], faceobjects[j][2])\n",
    "                inter_y2 = min(faceobjects[i][3], faceobjects[j][3])\n",
    "\n",
    "                inter_w = max(0, inter_x2 - inter_x1)\n",
    "                inter_h = max(0, inter_y2 - inter_y1)\n",
    "                inter_area = inter_w * inter_h\n",
    "                union_area = areas[i] + areas[j] - inter_area\n",
    "\n",
    "                iou = inter_area / union_area\n",
    "                if iou > nms_threshold:\n",
    "                    keep = False\n",
    "                    break\n",
    "\n",
    "            if keep:\n",
    "                picked.append(i)\n",
    "\n",
    "def evaluate_model(dataset_folder, annotations_file, model_param, model_bin):\n",
    "    net = NanoDet(model_param, model_bin)\n",
    "    \n",
    "    with open(annotations_file, 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "    \n",
    "    images = annotations['images']\n",
    "    ground_truths = annotations['annotations']\n",
    "\n",
    "    for img_info in images:\n",
    "        img_id = img_info['id']\n",
    "        img_file = os.path.join(dataset_folder, img_info['file_name'])\n",
    "        image = cv2.imread(img_file)\n",
    "        \n",
    "        gt_boxes = [ann for ann in ground_truths if ann['image_id'] == img_id]\n",
    "        gt_bboxes = [[ann['bbox'][0], ann['bbox'][1], ann['bbox'][2], ann['bbox'][3]] for ann in gt_boxes]\n",
    "\n",
    "        pred_boxes = net.detect(image)\n",
    "\n",
    "        # Calculate metrics like precision, recall, mAP, etc.\n",
    "        precision, recall, mAP = calculate_metrics(pred_boxes, gt_bboxes)\n",
    "        print(f'Image ID: {img_id}, Precision: {precision}, Recall: {recall}, mAP: {mAP}')\n",
    "\n",
    "def calculate_metrics(pred_boxes, gt_bboxes, iou_threshold=0.5):\n",
    "    def iou(box1, box2):\n",
    "        inter_x1 = max(box1[0], box2[0])\n",
    "        inter_y1 = max(box1[1], box2[1])\n",
    "        inter_x2 = min(box1[2], box2[2])\n",
    "        inter_y2 = min(box1[3], box2[3])\n",
    "\n",
    "        inter_w = max(0, inter_x2 - inter_x1)\n",
    "        inter_h = max(0, inter_y2 - inter_y1)\n",
    "        inter_area = inter_w * inter_h\n",
    "\n",
    "        box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "        return inter_area / union_area\n",
    "\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    for gt in gt_bboxes:\n",
    "        matched = False\n",
    "        for pred in pred_boxes:\n",
    "            if iou(gt, pred) >= iou_threshold:\n",
    "                tp += 1\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched:\n",
    "            fn += 1\n",
    "\n",
    "    fp = len(pred_boxes) - tp\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    ap = precision * recall  # Simplified AP calculation, adjust as needed\n",
    "\n",
    "    return precision, recall, ap\n",
    "\n",
    "\n",
    "# Example usage\n",
    "evaluate_model('dataset_128x128/valid', 'dataset_128x128/valid/_annotations.coco.json', 'nanodet_128x128_simplified-int8.param', 'nanodet_128x128_simplified-int8.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscodeyolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
